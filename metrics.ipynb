{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for running metrics on the generated images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.transforms.functional import normalize\n",
    "from torchvision.models.inception import inception_v3\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from scipy.stats import entropy\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('./dataset/image_caption_dataset_with_generated_images.pt', weights_only=False)\n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading done in batches to prevent memory flow issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(9), desc=\"Progress\"):\n",
    "    time.sleep(0.1)\n",
    "    data[i]['image'] = np.array(data[i]['image'][:, 70:290, 115:335].permute(1, 2, 0))\n",
    "    data[i]['image'] = cv2.resize(data[i]['image'], (4096, 4096), interpolation=cv2.INTER_LANCZOS4)\n",
    "    tqdm.write(f\"Done: {i+1}, Left: {len(data) - (i+1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(9), desc=\"Progress\"):\n",
    "    time.sleep(0.1)\n",
    "    data[i+9]['image'] = np.array(data[i+9]['image'][:, 70:290, 115:335].permute(1, 2, 0))\n",
    "    data[i+9]['image'] = cv2.resize(data[i+9]['image'], (4096, 4096), interpolation=cv2.INTER_LANCZOS4)\n",
    "    tqdm.write(f\"Done: {i+1}, Left: {len(data) - (i+1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(9), desc=\"Progress\"):\n",
    "    time.sleep(0.1)\n",
    "    data[i+18]['image'] = np.array(data[i+18]['image'][:, 70:290, 115:335].permute(1, 2, 0))\n",
    "    data[i+18]['image'] = cv2.resize(data[i+18]['image'], (4096, 4096), interpolation=cv2.INTER_LANCZOS4)\n",
    "    tqdm.write(f\"Done: {i+1}, Left: {len(data) - (i+1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data))\n",
    "plt.imshow(data[26]['image']) # 3, 220, 450\n",
    "data[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_image = np.array(data[26]['generated_image'])\n",
    "\n",
    "plt.imshow(gen_image) # 3, 220, 450\n",
    "gen_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path, is_gen):\n",
    "    data = torch.load(file_path)\n",
    "    if is_gen == False:\n",
    "        images = data['image']\n",
    "    else:\n",
    "        images = data['generated_image']\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(images, is_tensor = False, image_size=299):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "    if is_tensor:\n",
    "        images = [Image.fromarray(img.numpy()) for img in images]\n",
    "    print(type(transform(images[0])))\n",
    "    print(transform(images[0]).shape)\n",
    "    ans = torch.stack([transform(img) for img in images])\n",
    "    print(type(ans))\n",
    "    print(ans.shape)\n",
    "    return torch.stack([transform(img) for img in images])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Inception Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_inception_score(images, batch_size=8, splits=10, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    inception = inception_v3(pretrained=True, transform_input=False).to(device)\n",
    "    inception.eval()\n",
    "\n",
    "    def get_pred(x):\n",
    "        with torch.no_grad():\n",
    "            x = x.to(torch.float32) / 255.0\n",
    "\n",
    "            x = F.interpolate(x, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "\n",
    "            x = normalize(x, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            x = x.to(device)\n",
    "            preds = inception(x).softmax(dim=1)\n",
    "        return preds.cpu().numpy()\n",
    "\n",
    "    loader = DataLoader(TensorDataset(images), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    preds = np.concatenate([get_pred(batch[0]) for batch in loader], axis=0)\n",
    "\n",
    "    split_scores = []\n",
    "    for chunk in np.array_split(preds, splits):\n",
    "        p_y = np.mean(chunk, axis=0)\n",
    "        scores = [entropy(p_y, p) for p in chunk]\n",
    "        split_scores.append(np.exp(np.mean(scores)))\n",
    "\n",
    "    return np.mean(split_scores), np.std(split_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for FID score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fid(real_images, fake_images):\n",
    "    # device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    device = 'cpu'\n",
    "    fid = FrechetInceptionDistance(feature=2048).to(device)\n",
    "\n",
    "    fid.update(real_images.to(device), real=True)\n",
    "    fid.update(fake_images.to(device), real=False)\n",
    "\n",
    "    return fid.compute().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_images = torch.tensor(np.array([(data[i]['image'] * 255).clip(0, 255).astype('uint8') for i in range(len(data))]), dtype=torch.uint8).permute(0, 3, 1, 2)\n",
    "ground_truth_images.dtype, ground_truth_images.shape, ground_truth_images[0].shape, ground_truth_images[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = torch.tensor(np.array([np.array(data[i]['generated_image']) for i in range(len(data))]), dtype=torch.uint8).permute(0, 3, 1, 2)\n",
    "generated_images.dtype, generated_images.shape, generated_images[0].shape, generated_images[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_value = compute_fid(ground_truth_images, generated_images)\n",
    "\n",
    "print(f\"FID Score: {fid_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_mean, inception_std = compute_inception_score(generated_images)\n",
    "\n",
    "print(f\"Inception Score: {inception_mean} Â± {inception_std}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FODL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
